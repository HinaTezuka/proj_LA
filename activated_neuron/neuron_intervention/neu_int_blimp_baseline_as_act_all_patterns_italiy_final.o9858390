unfolded pickle
result_main: [{'Model': 'DeepMount00/Llama-3-8b-Ita', 'Task': 'existential_there_quantifiers_2', 'Accuracy': 0.818}, {'Model': 'DeepMount00/Llama-3-8b-Ita', 'Task': 'matrix_question_npi_licensor_present', 'Accuracy': 0.798}]
result_comp: [{'Model': 'DeepMount00/Llama-3-8b-Ita', 'Task': 'existential_there_quantifiers_2', 'Accuracy': 0.716}, {'Model': 'DeepMount00/Llama-3-8b-Ita', 'Task': 'matrix_question_npi_licensor_present', 'Accuracy': 0.749}]
result_comp_L1_or_L2: [{'Model': 'DeepMount00/Llama-3-8b-Ita', 'Task': 'existential_there_quantifiers_2', 'Accuracy': 0.793}, {'Model': 'DeepMount00/Llama-3-8b-Ita', 'Task': 'matrix_question_npi_licensor_present', 'Accuracy': 0.754}]
result_comp_L1_specific: [{'Model': 'DeepMount00/Llama-3-8b-Ita', 'Task': 'existential_there_quantifiers_2', 'Accuracy': 0.809}, {'Model': 'DeepMount00/Llama-3-8b-Ita', 'Task': 'matrix_question_npi_licensor_present', 'Accuracy': 0.734}]
                        Model                                  Task  Accuracy
0  DeepMount00/Llama-3-8b-Ita       existential_there_quantifiers_2     0.818
1  DeepMount00/Llama-3-8b-Ita  matrix_question_npi_licensor_present     0.798
                        Model                                  Task  Accuracy
0  DeepMount00/Llama-3-8b-Ita       existential_there_quantifiers_2     0.716
1  DeepMount00/Llama-3-8b-Ita  matrix_question_npi_licensor_present     0.749
                        Model                                  Task  Accuracy
0  DeepMount00/Llama-3-8b-Ita       existential_there_quantifiers_2     0.793
1  DeepMount00/Llama-3-8b-Ita  matrix_question_npi_licensor_present     0.754
                        Model                                  Task  Accuracy
0  DeepMount00/Llama-3-8b-Ita       existential_there_quantifiers_2     0.809
1  DeepMount00/Llama-3-8b-Ita  matrix_question_npi_licensor_present     0.734
                        Model  Accuracy
0  DeepMount00/Llama-3-8b-Ita     0.808
                        Model  Accuracy
0  DeepMount00/Llama-3-8b-Ita    0.7325
                        Model  Accuracy
0  DeepMount00/Llama-3-8b-Ita    0.7735
                        Model  Accuracy
0  DeepMount00/Llama-3-8b-Ita    0.7715
completed. saved to csv.

=================================== RESOURCE INFORMATION ===================================
 Requested Resource:
 mem=256000000kb,walltime=168:00:00,ncpus=26,place=pack 
 Used Resource: 
 mem=13493140kb,walltime=00:28:51,ncpus=26,cpupercent=154,vmem=48066736kb
============================================================================================
