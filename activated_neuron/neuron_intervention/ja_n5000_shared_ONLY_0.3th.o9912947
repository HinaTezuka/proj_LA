unfolded pickle: act_sum_dict
unfolded pickle: act_freq_base_dict
result_main: [{'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'adjunct_island', 'Accuracy': 0.907}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'anaphor_gender_agreement', 'Accuracy': 0.987}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'anaphor_number_agreement', 'Accuracy': 0.991}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'animate_subject_passive', 'Accuracy': 0.73}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'animate_subject_trans', 'Accuracy': 0.755}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'causative', 'Accuracy': 0.73}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'complex_NP_island', 'Accuracy': 0.576}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'coordinate_structure_constraint_complex_left_branch', 'Accuracy': 0.76}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'coordinate_structure_constraint_object_extraction', 'Accuracy': 0.838}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'determiner_noun_agreement_1', 'Accuracy': 0.941}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'determiner_noun_agreement_2', 'Accuracy': 0.971}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'determiner_noun_agreement_irregular_1', 'Accuracy': 0.797}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'determiner_noun_agreement_irregular_2', 'Accuracy': 0.924}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'determiner_noun_agreement_with_adj_2', 'Accuracy': 0.916}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'determiner_noun_agreement_with_adj_irregular_1', 'Accuracy': 0.81}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'determiner_noun_agreement_with_adj_irregular_2', 'Accuracy': 0.897}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'determiner_noun_agreement_with_adjective_1', 'Accuracy': 0.92}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'distractor_agreement_relational_noun', 'Accuracy': 0.743}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'distractor_agreement_relative_clause', 'Accuracy': 0.627}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'drop_argument', 'Accuracy': 0.494}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'ellipsis_n_bar_1', 'Accuracy': 0.762}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'ellipsis_n_bar_2', 'Accuracy': 0.955}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'existential_there_object_raising', 'Accuracy': 0.782}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'existential_there_quantifiers_1', 'Accuracy': 0.947}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'existential_there_quantifiers_2', 'Accuracy': 0.107}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'existential_there_subject_raising', 'Accuracy': 0.861}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'expletive_it_object_raising', 'Accuracy': 0.778}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'inchoative', 'Accuracy': 0.683}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'intransitive', 'Accuracy': 0.59}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'irregular_past_participle_adjectives', 'Accuracy': 0.988}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'irregular_past_participle_verbs', 'Accuracy': 0.898}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'irregular_plural_subject_verb_agreement_1', 'Accuracy': 0.877}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'irregular_plural_subject_verb_agreement_2', 'Accuracy': 0.832}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'left_branch_island_echo_question', 'Accuracy': 0.638}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'left_branch_island_simple_question', 'Accuracy': 0.874}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'matrix_question_npi_licensor_present', 'Accuracy': 0.311}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'npi_present_1', 'Accuracy': 0.646}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'npi_present_2', 'Accuracy': 0.715}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'only_npi_licensor_present', 'Accuracy': 0.666}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'only_npi_scope', 'Accuracy': 0.411}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'passive_1', 'Accuracy': 0.738}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'passive_2', 'Accuracy': 0.726}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'principle_A_c_command', 'Accuracy': 0.77}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'principle_A_case_1', 'Accuracy': 1.0}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'principle_A_case_2', 'Accuracy': 0.88}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'principle_A_domain_1', 'Accuracy': 0.997}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'principle_A_domain_2', 'Accuracy': 0.817}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'principle_A_domain_3', 'Accuracy': 0.649}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'principle_A_reconstruction', 'Accuracy': 0.422}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'regular_plural_subject_verb_agreement_1', 'Accuracy': 0.925}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'regular_plural_subject_verb_agreement_2', 'Accuracy': 0.869}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'sentential_negation_npi_licensor_present', 'Accuracy': 0.995}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'sentential_negation_npi_scope', 'Accuracy': 0.735}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'sentential_subject_island', 'Accuracy': 0.44}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'superlative_quantifiers_1', 'Accuracy': 0.851}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'superlative_quantifiers_2', 'Accuracy': 0.811}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'tough_vs_raising_1', 'Accuracy': 0.741}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'tough_vs_raising_2', 'Accuracy': 0.784}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'transitive', 'Accuracy': 0.75}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'wh_island', 'Accuracy': 0.662}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'wh_questions_object_gap', 'Accuracy': 0.844}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'wh_questions_subject_gap', 'Accuracy': 0.93}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'wh_questions_subject_gap_long_distance', 'Accuracy': 0.913}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'wh_vs_that_no_gap', 'Accuracy': 0.983}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'wh_vs_that_no_gap_long_distance', 'Accuracy': 0.975}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'wh_vs_that_with_gap', 'Accuracy': 0.263}, {'Model': 'tokyotech-llm/Llama-3-Swallow-8B-v0.1', 'Task': 'wh_vs_that_with_gap_long_distance', 'Accuracy': 0.237}]
                                    Model  ... Accuracy
0   tokyotech-llm/Llama-3-Swallow-8B-v0.1  ...    0.907
1   tokyotech-llm/Llama-3-Swallow-8B-v0.1  ...    0.987
2   tokyotech-llm/Llama-3-Swallow-8B-v0.1  ...    0.991
3   tokyotech-llm/Llama-3-Swallow-8B-v0.1  ...    0.730
4   tokyotech-llm/Llama-3-Swallow-8B-v0.1  ...    0.755
..                                    ...  ...      ...
62  tokyotech-llm/Llama-3-Swallow-8B-v0.1  ...    0.913
63  tokyotech-llm/Llama-3-Swallow-8B-v0.1  ...    0.983
64  tokyotech-llm/Llama-3-Swallow-8B-v0.1  ...    0.975
65  tokyotech-llm/Llama-3-Swallow-8B-v0.1  ...    0.263
66  tokyotech-llm/Llama-3-Swallow-8B-v0.1  ...    0.237

[67 rows x 3 columns]
                                   Model  Accuracy
0  tokyotech-llm/Llama-3-Swallow-8B-v0.1  0.766299
intervention num: 5000
THRESHOLD: 0.3
completed. saved to csv.

=================================== RESOURCE INFORMATION ===================================
 Requested Resource:
 mem=256000000kb,walltime=168:00:00,ncpus=26,place=pack 
 Used Resource: 
 mem=17160480kb,walltime=09:07:21,ncpus=26,cpupercent=100,vmem=48467892kb
============================================================================================
